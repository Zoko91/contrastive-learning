{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Contrastive Learning"
   ],
   "metadata": {
    "id": "SF-R92oKYOvg"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "model_name = \"CLR - 01\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T10:59:13.591748366Z",
     "start_time": "2023-12-13T10:59:13.399801221Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "!pip install torch torchvision"
   ],
   "metadata": {
    "id": "S0dxH2HSYVGY",
    "ExecuteTime": {
     "end_time": "2023-12-13T10:59:15.281063255Z",
     "start_time": "2023-12-13T10:59:13.405080779Z"
    }
   },
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import cosine_similarity\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import csv"
   ],
   "metadata": {
    "id": "Q2l_5Xoha8Iv",
    "ExecuteTime": {
     "end_time": "2023-12-13T10:59:15.325275380Z",
     "start_time": "2023-12-13T10:59:15.324966018Z"
    }
   },
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T10:59:15.325491701Z",
     "start_time": "2023-12-13T10:59:15.325152754Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Set random seed\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Usual transformations\n",
    "transform_load = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Data augmentation\n",
    "def get_transformed_augmented(val):\n",
    "    if val < 0.5:\n",
    "        return transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=224 ,scale=(0.7, 1.0), ratio=(0.8, 1.2)),\n",
    "        transforms.RandomHorizontalFlip(0.3),\n",
    "    ])\n",
    "    return transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(0.3),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1,\n",
    "                                  saturation=0.1, hue=0.05)\n",
    "    ])\n",
    "\n",
    "# Get the subset dataset and calculate the mean and std\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_load)\n",
    "train_size = 5000\n",
    "subset_indices = np.random.choice(len(train_dataset), train_size, replace=False)\n",
    "subset_dataset = torch.utils.data.Subset(train_dataset, subset_indices)\n",
    "\n",
    "val_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_load)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T10:59:16.570617392Z",
     "start_time": "2023-12-13T10:59:15.325243079Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "def get_transforms(means, stds):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(means, stds),\n",
    "    ])\n",
    "    return transform\n",
    "\n",
    "# Calculate the mean and std of the subset dataset\n",
    "def get_mean_std(dataset):\n",
    "    \"\"\"Compute the mean and std value of dataset.\"\"\"\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=2)\n",
    "    mean = torch.zeros(3)\n",
    "    std = torch.zeros(3)\n",
    "    print('==> Computing mean and std..')\n",
    "    for inputs, targets in dataloader:\n",
    "        for i in range(3):\n",
    "            mean[i] += inputs[:, i, :, :].mean()\n",
    "            std[i] += inputs[:, i, :, :].std()\n",
    "    mean.div_(len(dataset))\n",
    "    std.div_(len(dataset))\n",
    "    return mean, std"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T10:59:16.642459174Z",
     "start_time": "2023-12-13T10:59:16.574028636Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Computing mean and std..\n",
      "Means: tensor([0.4902, 0.4795, 0.4439])\n",
      "Standard deviations: tensor([0.1948, 0.1929, 0.1945])\n",
      "\n",
      "==> Computing mean and std..\n",
      "Validation means: tensor([0.4942, 0.4851, 0.4504])\n",
      "Validation standard deviations: tensor([0.1949, 0.1922, 0.1944])\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean and std of the subset dataset\n",
    "train_means, train_stds = get_mean_std(subset_dataset)\n",
    "print(f'Means: {train_means}')\n",
    "print(f'Standard deviations: {train_stds}\\n')\n",
    "val_means, val_stds = get_mean_std(val_dataset)\n",
    "print(f'Validation means: {val_means}')\n",
    "print(f'Validation standard deviations: {val_stds}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T10:59:32.814093353Z",
     "start_time": "2023-12-13T10:59:16.620988477Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "%%capture\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=get_transforms(train_means,train_stds))\n",
    "train_size = 5000\n",
    "subset_indices = np.random.choice(len(train_dataset), train_size, replace=False)\n",
    "subset_dataset = torch.utils.data.Subset(train_dataset, subset_indices)\n",
    "val_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=get_transforms(val_means,val_stds))\n",
    "\n",
    "# Data Loader\n",
    "train_loader = DataLoader(subset_dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T10:59:34.053307273Z",
     "start_time": "2023-12-13T10:59:32.814456709Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Contrastive Model"
   ],
   "metadata": {
    "id": "TU_IF3rdpqTU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.1):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, z1, z2, z_list):\n",
    "        # Calculate cosine similarity\n",
    "        similarity_pair = cosine_similarity(z1, z2, dim=-1) / self.temperature\n",
    "\n",
    "        # Calculate the cosine similarity for each pair of z1 and... but not z1 and z1\n",
    "        similarities = torch.stack([cosine_similarity(z1, rep, dim=-1) / self.temperature for rep in z_list if not torch.equal(rep, z1)])\n",
    "        \n",
    "        if similarities.numel() == 0:\n",
    "            return torch.tensor(0.0, device=z1.device, requires_grad=True)\n",
    "        \n",
    "        # Numerator is exp(similarity_pair)\n",
    "        exp_similarity = torch.exp(similarity_pair)\n",
    "\n",
    "        # Denominator is sum(exp(list_similarity_pair))\n",
    "        exp_similarities = torch.sum(torch.exp(similarities))\n",
    "\n",
    "        # Apply log-sum-exp trick\n",
    "        loss = -torch.log(exp_similarity / (exp_similarities + exp_similarity))\n",
    "        \n",
    "        if torch.isnan(loss):\n",
    "            return torch.tensor(0.0, device=z1.device, requires_grad=True)\n",
    "            \n",
    "        return torch.mean(loss)  # Compute the mean of the loss"
   ],
   "metadata": {
    "id": "b5ThCO2Kp0ee",
    "ExecuteTime": {
     "end_time": "2023-12-13T10:59:34.057629310Z",
     "start_time": "2023-12-13T10:59:34.055314796Z"
    }
   },
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.base_model = base_model\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        z1 = self.base_model(x1)\n",
    "        z2 = self.base_model(x2)\n",
    "        return z1, z2"
   ],
   "metadata": {
    "id": "2vthegBPp7KD",
    "ExecuteTime": {
     "end_time": "2023-12-13T10:59:34.101275384Z",
     "start_time": "2023-12-13T10:59:34.058510750Z"
    }
   },
   "execution_count": 38,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class SimpleResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleResNet, self).__init__()\n",
    "        self.resnet = torchvision.models.resnet18()\n",
    "        self.resnet.fc = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)"
   ],
   "metadata": {
    "id": "YT67ux7Sp9en",
    "ExecuteTime": {
     "end_time": "2023-12-13T10:59:34.101474115Z",
     "start_time": "2023-12-13T10:59:34.100963553Z"
    }
   },
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = SiameseNetwork(SimpleResNet())\n",
    "learning_rate = 0.0001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = ContrastiveLoss()"
   ],
   "metadata": {
    "id": "9wsijZ73qEMr",
    "ExecuteTime": {
     "end_time": "2023-12-13T10:59:34.196267379Z",
     "start_time": "2023-12-13T10:59:34.101120552Z"
    }
   },
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "num_epochs = 30\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ],
   "metadata": {
    "id": "zxiGO8aJqP7f",
    "ExecuteTime": {
     "end_time": "2023-12-13T10:59:34.241216801Z",
     "start_time": "2023-12-13T10:59:34.198701160Z"
    }
   },
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "loss_history = []\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "\n",
    "        images, _ = data\n",
    "        images = images.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Initialize total loss for the batch\n",
    "        batch_loss = torch.tensor(0.0, device=device, requires_grad=True)\n",
    "\n",
    "        # Create tuples of transformed images for each image of the batch and put all the zk, zk+1 in a list (feed forward network)\n",
    "        zk_list = []\n",
    "        for image in images:\n",
    "            transformation1 = get_transformed_augmented(np.random.rand())\n",
    "            transformation2 = get_transformed_augmented(np.random.rand())\n",
    "            transformed_image1 = transformation1(image).to(device)\n",
    "            transformed_image2 = transformation2(image).to(device)\n",
    "\n",
    "            z1, z2 = model(transformed_image1.unsqueeze(0), transformed_image2.unsqueeze(0))\n",
    "            zk_list.append(z1)\n",
    "            zk_list.append(z2)\n",
    "            \n",
    "\n",
    "        # Process each image in the batch\n",
    "        for i in range(0, len(zk_list), 2):\n",
    "            # Calculate loss for both the first transformed image and second\n",
    "            loss1 = criterion(zk_list[i], zk_list[i+1], zk_list)\n",
    "            loss2 = criterion(zk_list[i+1], zk_list[i], zk_list)\n",
    "            batch_loss = batch_loss + (loss1 + loss2)\n",
    "        \n",
    "        # Backward pass\n",
    "        batch_loss.backward()\n",
    "\n",
    "        # Update weights after processing the entire batch\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += batch_loss.item() / 2*len(images)\n",
    "\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {average_loss}')\n",
    "    loss_history.append(average_loss)\n",
    "\n",
    "print('Training finished.')\n",
    "elapsed_time = time.time() - start_time"
   ],
   "metadata": {
    "id": "YhJhZdsdqHYR",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "793a192b-d439-4d34-ef7d-cf802b017e67",
    "ExecuteTime": {
     "end_time": "2023-12-13T11:17:17.045210019Z",
     "start_time": "2023-12-13T10:59:34.241072309Z"
    }
   },
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 3.2946133353233336\n",
      "Epoch 2/10, Loss: 2.975377888059616\n",
      "Epoch 3/10, Loss: 2.9372630626678466\n",
      "Epoch 4/10, Loss: 2.9112550132751465\n",
      "Epoch 5/10, Loss: 2.8903063905715944\n",
      "Epoch 6/10, Loss: 2.891204967212677\n",
      "Epoch 7/10, Loss: 2.868584390258789\n",
      "Epoch 8/10, Loss: 2.8640765580177305\n",
      "Epoch 9/10, Loss: 2.854138064289093\n",
      "Epoch 10/10, Loss: 2.8503780041217803\n",
      "Training finished.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "torch.save(model.base_model.state_dict(), model_name+'.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T11:17:17.065867601Z",
     "start_time": "2023-12-13T11:17:17.045039705Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plotting the loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)\n",
    "plt.title('Contrastive Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T11:17:17.316132097Z",
     "start_time": "2023-12-13T11:17:17.067450438Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification Head\n"
   ],
   "metadata": {
    "id": "A7F6YefhRHNA"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Usual MLP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define transformation to convert CIFAR-10 images to grayscale\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "train_dataset_mlp = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset_mlp = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Define data loaders\n",
    "batch_size_mlp = 64"
   ],
   "metadata": {
    "id": "pQ1mFEG9bfFv",
    "ExecuteTime": {
     "end_time": "2023-12-13T11:17:18.531197393Z",
     "start_time": "2023-12-13T11:17:17.296986120Z"
    }
   },
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Calculate the mean and std of the subset dataset\n",
    "train_means_mlp, train_stds_mlp = get_mean_std(train_dataset_mlp)\n",
    "print(f'Means: {train_means_mlp}')\n",
    "print(f'Standard deviations: {train_stds_mlp}\\n')\n",
    "val_means_mlp, val_stds_mlp = get_mean_std(test_dataset_mlp)\n",
    "print(f'Validation means: {val_means_mlp}')\n",
    "print(f'Validation standard deviations: {val_stds_mlp}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T11:17:56.597125204Z",
     "start_time": "2023-12-13T11:17:18.570790768Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "%%capture\n",
    "train_dataset_mlp = datasets.CIFAR10(root='./data', train=True, download=True, transform=get_transforms(train_means_mlp,train_stds_mlp))\n",
    "val_dataset_mlp = datasets.CIFAR10(root='./data', train=False, download=True, transform=get_transforms(val_means_mlp,val_stds_mlp))\n",
    "\n",
    "# Data Loader\n",
    "train_loader_mlp = DataLoader(train_dataset_mlp, batch_size=batch_size_mlp, shuffle=True, num_workers=2)\n",
    "test_loader_mlp = DataLoader(val_dataset_mlp, batch_size=batch_size_mlp, shuffle=False, num_workers=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T11:17:57.803290328Z",
     "start_time": "2023-12-13T11:17:56.596991678Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Our SimCLR model with MLP Head"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "%%capture\n",
    "clr_base_model = SimpleResNet()\n",
    "clr_base_model.load_state_dict(torch.load(model_name+'.pth'))\n",
    "clr_base_model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T11:17:57.970867128Z",
     "start_time": "2023-12-13T11:17:57.805122150Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "class MLPHead(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(MLPHead, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Define the full model with contrastive feature extractor and MLP head\n",
    "class ContrastiveMLPModel(nn.Module):\n",
    "    def __init__(self, feature_extractor, mlp_head):\n",
    "        super(ContrastiveMLPModel, self).__init__()\n",
    "        self.base_model = feature_extractor\n",
    "        self.mlp_model = mlp_head\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.base_model(x)\n",
    "        return self.mlp_model(features.view(features.size(0), -1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T11:17:57.978899910Z",
     "start_time": "2023-12-13T11:17:57.973632855Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Output size of base model: torch.Size([1, 512])\n",
    "input_size_for_mlp = 512\n",
    "\n",
    "# Define the MLP head for classification\n",
    "mlp_head = MLPHead(input_size_for_mlp, hidden_size=256, num_classes=10)\n",
    "\n",
    "# Combine the feature extractor and MLP head into the full model\n",
    "contrastive_mlp_model = ContrastiveMLPModel(clr_base_model, mlp_head)\n",
    "contrastive_mlp_model.base_model.requires_grad = False\n",
    "\n",
    "# Define the optimizer\n",
    "mlp_lr = 0.001\n",
    "optimizer = torch.optim.Adam(contrastive_mlp_model.mlp_model.parameters(), lr=mlp_lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the training loop\n",
    "num_epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "contrastive_mlp_model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T11:17:58.004131862Z",
     "start_time": "2023-12-13T11:17:57.976115657Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Classification Loss: 0.6146322797298431\n",
      "Epoch 2/10, Classification Loss: 0.5672034719467163\n",
      "Epoch 3/10, Classification Loss: 0.5518818436145783\n",
      "Epoch 4/10, Classification Loss: 0.542935531949997\n",
      "Epoch 5/10, Classification Loss: 0.5352910989284515\n",
      "Epoch 6/10, Classification Loss: 0.5297916806697845\n",
      "Epoch 7/10, Classification Loss: 0.5254642563343048\n",
      "Epoch 8/10, Classification Loss: 0.5212735776424408\n",
      "Epoch 9/10, Classification Loss: 0.5178605819702149\n",
      "Epoch 10/10, Classification Loss: 0.5145853198051452\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    contrastive_mlp_model.train()\n",
    "    total_classification_loss = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader_mlp):\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero the gradients only for the parameters that require grad (MLP head)\n",
    "        contrastive_mlp_model.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        predictions = contrastive_mlp_model(images)\n",
    "\n",
    "        # Calculate classification loss using CrossEntropyLoss\n",
    "        classification_loss = criterion(predictions, labels)\n",
    "        total_classification_loss += classification_loss.item()\n",
    "\n",
    "\n",
    "        # Backward pass and update weights for the MLP head only\n",
    "        classification_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    average_classification_loss = total_classification_loss / len(train_loader)\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Classification Loss: {average_classification_loss}')\n",
    "\n",
    "print('Training finished.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T11:33:41.018192820Z",
     "start_time": "2023-12-13T11:17:58.000206624Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 157/157 [00:07<00:00, 20.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.4108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "contrastive_mlp_model.eval()\n",
    "correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_loader_mlp, desc='Testing'):\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = contrastive_mlp_model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "mlp_accuracy = correct / total_samples\n",
    "print(f'Test Accuracy: {mlp_accuracy}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T11:33:48.801382320Z",
     "start_time": "2023-12-13T11:33:41.017025505Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using a more complex architecture of FC layers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define transformation to convert CIFAR-10 images to grayscale\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "train_dataset_fc = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset_fc = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T11:33:50.038766896Z",
     "start_time": "2023-12-13T11:33:48.801071058Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Computing mean and std..\n",
      "Means: tensor([0.4914, 0.4822, 0.4465])\n",
      "Standard deviations: tensor([0.2023, 0.1994, 0.2010])\n",
      "\n",
      "==> Computing mean and std..\n",
      "Validation means: tensor([0.4942, 0.4851, 0.4504])\n",
      "Validation standard deviations: tensor([0.2020, 0.1991, 0.2011])\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean and std of the subset dataset\n",
    "train_means_fc, train_stds_fc = get_mean_std(train_dataset_fc)\n",
    "print(f'Means: {train_means_fc}')\n",
    "print(f'Standard deviations: {train_stds_fc}\\n')\n",
    "val_means_fc, val_stds_fc = get_mean_std(test_dataset_fc)\n",
    "print(f'Validation means: {val_means_fc}')\n",
    "print(f'Validation standard deviations: {val_stds_fc}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T11:34:28.151951169Z",
     "start_time": "2023-12-13T11:33:50.039978444Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Apply transformations\n",
    "train_dataset_fc = datasets.CIFAR10(root='./data', train=True, download=True, transform=get_transforms(train_means_fc,train_stds_fc))\n",
    "val_dataset_fc = datasets.CIFAR10(root='./data', train=False, download=True, transform=get_transforms(val_means_fc,val_stds_fc))\n",
    "\n",
    "# Data Loader\n",
    "train_loader_fc = DataLoader(train_dataset_fc, batch_size=batch_size_mlp, shuffle=True, num_workers=2)\n",
    "test_loader_fc = DataLoader(val_dataset_fc, batch_size=batch_size_mlp, shuffle=False, num_workers=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T11:34:29.338374534Z",
     "start_time": "2023-12-13T11:34:28.152919366Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Our SimCLR model with FC Head"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "%%capture\n",
    "clr_base_model_for_fc = SimpleResNet()\n",
    "clr_base_model_for_fc.load_state_dict(torch.load(model_name+'.pth'))\n",
    "clr_base_model_for_fc.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T11:34:29.505085111Z",
     "start_time": "2023-12-13T11:34:29.340889150Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "class FCHead(nn.Module):\n",
    "    def __init__(self, input_size=512, num_classes=10):\n",
    "        super(FCHead, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.fc1 = nn.Linear(self.input_size, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class ContrastiveFCModel(nn.Module):\n",
    "    def __init__(self, feature_extractor, fc_head):\n",
    "        super(ContrastiveFCModel, self).__init__()\n",
    "        self.base_model = feature_extractor\n",
    "        self.fc_model = fc_head\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.base_model(x)\n",
    "        return self.fc_model(features.view(features.size(0), -1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T11:34:29.515449451Z",
     "start_time": "2023-12-13T11:34:29.505757228Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Define the CNN head for classification\n",
    "fc_head = FCHead(input_size=512, num_classes=10)\n",
    "\n",
    "# Combine the feature extractor and MLP head into the full model\n",
    "contrastive_fc_model = ContrastiveFCModel(clr_base_model_for_fc, fc_head)\n",
    "contrastive_fc_model.base_model.requires_grad = False\n",
    "\n",
    "# Define the optimizer\n",
    "mlp_lr = 0.001\n",
    "optimizer = torch.optim.Adam(contrastive_fc_model.fc_model.parameters(), lr=mlp_lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the training loop\n",
    "num_epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "contrastive_fc_model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T11:34:29.544093772Z",
     "start_time": "2023-12-13T11:34:29.513859849Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Classification Loss: 0.5858645562648773\n",
      "Epoch 2/10, Classification Loss: 0.558238417673111\n",
      "Epoch 3/10, Classification Loss: 0.5484469312191009\n",
      "Epoch 4/10, Classification Loss: 0.5416579977512359\n",
      "Epoch 5/10, Classification Loss: 0.5360598414421082\n",
      "Epoch 6/10, Classification Loss: 0.5309843094825745\n",
      "Epoch 7/10, Classification Loss: 0.5283968874931335\n",
      "Epoch 8/10, Classification Loss: 0.5249115033149719\n",
      "Epoch 9/10, Classification Loss: 0.522894117641449\n",
      "Epoch 10/10, Classification Loss: 0.5199760732173919\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    contrastive_fc_model.train()\n",
    "    total_classification_loss = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader_fc):\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero the gradients only for the parameters that require grad (FC head)\n",
    "        contrastive_fc_model.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        predictions = contrastive_fc_model(images)\n",
    "\n",
    "        # Calculate classification loss using CrossEntropyLoss\n",
    "        classification_loss = criterion(predictions, labels)\n",
    "        total_classification_loss += classification_loss.item()\n",
    "\n",
    "        # Backward pass and update weights for the FC head only\n",
    "        classification_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    average_classification_loss = total_classification_loss / len(train_loader)\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Classification Loss: {average_classification_loss}')\n",
    "\n",
    "print('Training finished.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T11:50:12.705535617Z",
     "start_time": "2023-12-13T11:34:29.543673598Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 157/157 [00:07<00:00, 20.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.4191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the test set\n",
    "contrastive_fc_model.eval()\n",
    "correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_loader_fc, desc='Testing'):\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = contrastive_fc_model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "fc_accuracy = correct / total_samples\n",
    "print(f'Test Accuracy: {fc_accuracy}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T11:50:20.401409865Z",
     "start_time": "2023-12-13T11:50:12.704965171Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ADD TO CSV"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "with open('results.csv', 'a') as f:\n",
    "    f.write(\"\"+str(model_name)+','+str(batch_size)+','+str(np.round(elapsed_time,3))+','+str(np.round(loss_history[-1],3))+','+str(np.round(mlp_accuracy,3))+','+str(np.round(fc_accuracy,3))+'\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T13:01:21.997214819Z",
     "start_time": "2023-12-13T13:01:21.955844553Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
